{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set  up  accounts and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append('./src')\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setup image and instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_custom_image_name=\"image-embedding:gpu-1.1.0-201909300947\"\n",
    "instance_type = \"ml.p3.2xlarge\" \n",
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account_id, region, pytorch_custom_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Configure train/ test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker_session.default_bucket()\n",
    "raw_bucket=\"aegovansagemaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_raw = \"s3://{}/merket1501/bounding_box_train/\".format(raw_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train=\"s3://{}/market1501/train3/\".format(bucket)\n",
    "s3_train_lst=\"s3://{}/market1501/train3_lst/\".format(bucket)\n",
    "\n",
    "\n",
    "s3_val=\"s3://{}/market1501/val3/\".format(bucket)\n",
    "s3_val_lst=\"s3://{}/market1501/val3_lst/\".format(bucket)\n",
    "\n",
    "\n",
    "s3_output_path= \"s3://{}/market1501_output/\".format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir=\"/tmp/imageebedding\"\n",
    "train_raw_dir = os.path.join(temp_dir, \"train_raw\")\n",
    "train_lst= os.path.join(temp_dir, \"train_raw\", \"train.lst\")\n",
    "val_raw_dir = os.path.join(temp_dir, \"val_raw\")\n",
    "val_lst= os.path.join(temp_dir, \"val_raw\", \"val.lst\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $temp_dir \n",
    "!mkdir  -p $temp_dir \n",
    "!mkdir -p  $train_raw_dir\n",
    "!mkdir -p  $val_raw_dir\n",
    "!aws s3 sync $s3_train_raw $train_raw_dir --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.market1501_dataset import Market1501Dataset\n",
    "\n",
    "dataset = Market1501Dataset(train_raw_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [os.path.join(train_raw_dir, f) for f in os.listdir(train_raw_dir) if f.endswith(\".jpg\")]\n",
    "\n",
    "# The market 1501 dataset files have the naming convention target_camerasite_..., e.g. 1038_c2s2_131202_03.jpeg\n",
    "target_raw_labels = [os.path.basename(f).split(\"_\")[0] for f in files]\n",
    "zero_indexed_labels_dict = {}\n",
    "for rc in target_raw_labels:\n",
    "    zero_indexed_labels_dict[rc] = zero_indexed_labels_dict.get(rc, len(zero_indexed_labels_dict))\n",
    "\n",
    "target_zero_indexed_labels = [zero_indexed_labels_dict[l] for l in target_raw_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3://sagemaker-us-east-2-324346001917/market1501/train/\n",
    "len(zero_indexed_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_train, class_val = train_test_split( list(zero_indexed_labels_dict.values()),  test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datatrain_x = [f for f,l in zip(files, target_zero_indexed_labels) if l in class_train]\n",
    "datatrain_y = [l for f,l in zip(files, target_zero_indexed_labels) if l in class_train]\n",
    "\n",
    "\n",
    "dataval_x = [f for f,l in zip(files, target_zero_indexed_labels) if l in class_val]\n",
    "dataval_y = [l for f,l in zip(files, target_zero_indexed_labels) if l in class_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.DataFrame.from_records([(i,)for i in dataval_y])\n",
    "df_val.columns=[\"target\"]\n",
    "df_train = pd.DataFrame.from_records([(i,)for i in datatrain_y])\n",
    "df_train.columns=[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"target\"].value_counts().plot.bar(figsize=(20,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"target\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"target\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"target\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def upload_files(files, s3_dest, num_threads=10 ):\n",
    "    input_tuples = ( (f,  s3_dest) for f in files)\n",
    "\n",
    "    with ThreadPool(num_threads) as pool:\n",
    "        pool.starmap(upload_file, input_tuples)\n",
    "   \n",
    "    \n",
    "\n",
    "def upload_file(f, s3_dest):\n",
    "    fname=os.path.basename(f)\n",
    "    prefix = \"/\".join( s3_dest.split(\"//\")[1].split(\"/\")[1:])\n",
    "    key = \"{}/{}\".format(prefix.strip(\"/\"), fname)\n",
    "    bucket_d = s3_dest.split(\"//\")[1].split(\"/\")[0]\n",
    "    s3_client.upload_file(f,   bucket_d, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "upload_files(dataval_x, s3_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "upload_files(datatrain_x, s3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train, s3_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A .lst file is a tab-separated file with three columns that contains a list of image files. The first column specifies the image index, the second column specifies the class label index for the image, and the third column specifies the relative path of the image file. The image index in the first column should be unique across all of the images. Here we make an image list file using the im2rec tool from MXNet. You can also create the .lst file in your own way. An example of .lst file is shown as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_lst_file(x, y, dest_lst_file):\n",
    "#     with open(dest_lst_file, \"w\") as f:\n",
    "#         for i, (x,y) in enumerate(zip(x, y)):\n",
    "#             line = \"{}\\t{}\\t{}\\n\".format(i, y, x)\n",
    "#             f.write(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_lst_file([x.lstrip(val_raw_dir) for x in dataval_x], dataval_y, val_lst)\n",
    "# create_lst_file([x.lstrip(train_raw_dir) for x in datatrain_x], datatrain_y, train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload_file(val_lst, s3_val_lst)\n",
    "# upload_file(train_lst, s3_train_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !head $train_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"train\" : s3_train,\n",
    "    \"val\" :s3_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"dataset\":\"Market1501TripletFactory\",\n",
    "    \"batchsize\": \"64\",\n",
    "    \"epochs\" : \"1000\",\n",
    "    \"learning_rate\":.0001,\n",
    "    \"weight_decay\":5e-5,\n",
    "    \"momentum\":.9,\n",
    "    \"patience\": 20,\n",
    "    \"log-level\" : \"INFO\",\n",
    "    \"tripletloss_margin\":500\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [{\"Name\": \"TrainLoss\",\n",
    "                     \"Regex\": \"###score: train_loss### (\\d*[.]?\\d*)\"}\n",
    "                    ,{\"Name\": \"ValidationLoss\",\n",
    "                     \"Regex\": \"###score: val_loss### (\\d*[.]?\\d*)\"}\n",
    "                    ,{\"Name\": \"TrainScore\",\n",
    "                     \"Regex\": \"###score: train_score### (\\d*[.]?\\d*)\"}\n",
    "                   ,{\"Name\": \"ValidationScore\",\n",
    "                     \"Regex\": \"###score: val_score### (\\d*[.]?\\d*)\"}\n",
    "                    ,{\"Name\": \"trainVariance\",\n",
    "                     \"Regex\": \"###score: train_loss_std### (\\d*[.]?\\d*)\"}\n",
    "                    ,{\"Name\": \"ValVariance\",\n",
    "                     \"Regex\": \"###score: val_loss_std### (\\d*[.]?\\d*)\"}\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commit ebb7a712a4177a8d911498ab41b3617e4b8f3b0c\n",
      "    Set k==1\n"
     ]
    }
   ],
   "source": [
    "!git log -1| head -1\n",
    "!git log -1| tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "git_config = {'repo': 'https://github.com/elangovana/image-embedding.git',\n",
    "              'branch': 'master',\n",
    "              'commit': 'ebb7a712a4177a8d911498ab41b3617e4b8f3b0c'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(\n",
    "     entry_point='experiment_train.py',\n",
    "                    source_dir = 'src',\n",
    "                    dependencies =['src/datasets', 'src/evaluators'],\n",
    "                    role=role,\n",
    "                    framework_version =\"1.0.0\",\n",
    "                    py_version='py3',\n",
    "                    git_config= git_config,\n",
    "                    image_name= docker_repo,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type=instance_type,\n",
    "                    hyperparameters =hyperparameters,\n",
    "                    output_path=s3_output_path,\n",
    "                    metric_definitions=metric_definitions,\n",
    "                    #train_use_spot_instances = True\n",
    "                    base_job_name =\"image-embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
